{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using Conditional Random Fields\n",
    "\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "\n",
    "The objective is to build an entity recognition model to predict various entities/phrases from unstructured text. \n",
    "\n",
    "The data consists of a set of sentences (sequences) each of which contains a series of words (e.g., 'Zamibian', 'officials') and the respective IOB labels (e.g., 'B-gpe', 'O').  \n",
    "\n",
    "Quick peek of the dataset below\n",
    "\n",
    "\n",
    "| sentence_id  | word       | Tag     \n",
    "|--------------|------------|-------\n",
    "| 704          | Zamibian   | B-gpe   \n",
    "| 704          | officials  | O       \n",
    "| 704          | say        | O    \n",
    "\n",
    "\n",
    "The entities to be recognized are as follow  \n",
    "\n",
    "nat -> Natural Phenomenon  \n",
    "gpe -> Geopolitical  \n",
    "tim -> Time   \n",
    "geo -> Geographical   \n",
    "org -> Organization  \n",
    "per -> Person  \n",
    "art -> Artifact  \n",
    "eve -> Event  \n",
    "\n",
    "The target variable to predict is Tag and it follows the below convention.  \n",
    "B-{ } : Beginning of an entity phrase  \n",
    "I-{ } : Inside an entity phrase  \n",
    "O     : Outside      \n",
    "\n",
    "We will predict the entities using **Conditional Random Fields**.\n",
    "  \n",
    "Conditional Random Field is a standard model for predicting the most likely sequence of labels that correspond to a sequence of inputs.\n",
    "\n",
    "\n",
    "### Environment set-up\n",
    "\n",
    "Install the libraries defined in `requirements.txt` file using the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.16.5)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: nltk in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.4.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->-r requirements.txt (line 3)) (4.43.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->-r requirements.txt (line 3)) (0.8.6)\n",
      "Requirement already satisfied: six in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->-r requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\vinubalan\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->-r requirements.txt (line 3)) (0.9.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vinubalan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vinubalan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option(\"display.max_colwidth\", 30)\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "\n",
    "# Text feature extraction - Custom functions defined in utils.py\n",
    "from utils import sent2features\n",
    "\n",
    "# Modeling Algorithm\n",
    "import sklearn_crfsuite\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import scorers, metrics\n",
    "\n",
    "# Saving and loading Model \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46464, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704</td>\n",
       "      <td>Zambian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704</td>\n",
       "      <td>officials</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704</td>\n",
       "      <td>say</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704</td>\n",
       "      <td>reports</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>that</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id       word    Tag\n",
       "0          704    Zambian  B-gpe\n",
       "1          704  officials      O\n",
       "2          704        say      O\n",
       "3          704    reports      O\n",
       "4          704       that      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_new.txt\", sep = \"\\s+\",quoting=csv.QUOTE_NONE)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "df_new =  df.head(100).drop(columns = ['sentence_id','Tag'])\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(df_new.to_dict('records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zambian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>officials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word\n",
       "0    Zambian\n",
       "1  officials\n",
       "2        say\n",
       "3    reports\n",
       "4       that"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.word.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentences : 2099 , Unique words :7310\n",
      "\n",
      "Proportion of Tags\n",
      "O        84.92\n",
      "B-geo     3.11\n",
      "I-per     1.90\n",
      "B-org     1.87\n",
      "B-gpe     1.87\n",
      "B-tim     1.75\n",
      "B-per     1.67\n",
      "I-org     1.43\n",
      "I-geo     0.61\n",
      "I-tim     0.49\n",
      "B-art     0.09\n",
      "B-eve     0.08\n",
      "I-eve     0.06\n",
      "I-art     0.06\n",
      "I-gpe     0.05\n",
      "B-nat     0.03\n",
      "I-nat     0.01\n",
      "Name: Tag, dtype: float64\n",
      "\n",
      "Proportion of Tags excluding'O'\n",
      "B-geo    20.62\n",
      "I-per    12.61\n",
      "B-org    12.43\n",
      "B-gpe    12.39\n",
      "B-tim    11.57\n",
      "B-per    11.07\n",
      "I-org     9.47\n",
      "I-geo     4.05\n",
      "I-tim     3.22\n",
      "B-art     0.57\n",
      "B-eve     0.51\n",
      "I-eve     0.43\n",
      "I-art     0.41\n",
      "I-gpe     0.36\n",
      "B-nat     0.20\n",
      "I-nat     0.07\n",
      "Name: Tag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique sentences : {} , Unique words :{}\\n\".format(df.sentence_id.nunique(), df.word.nunique()))\n",
    "\n",
    "print(\"Proportion of Tags\")\n",
    "print(np.round(df.Tag.value_counts(normalize = True),4)*100)\n",
    "print(\"\\nProportion of Tags excluding'O'\")\n",
    "print(np.round(df[df.Tag != 'O'].Tag.value_counts(normalize = True),4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of 'O' is ~85% and outweighs all other tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing\n",
    "\n",
    "For each sentence, we will retrieve tokens and their corresponding tags using the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Sentence Words Sequence\n",
      " ['Zambian', 'officials', 'say', 'reports', 'that', 'President', 'Levy', 'Mwanawasa', 'has', 'died', 'are', 'FALSE', '.']\n",
      "First Sentence Tags\n",
      " ['B-gpe', 'O', 'O', 'O', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "y = []\n",
    "\n",
    "# for each sentence ID, extract\n",
    "# 1. List of words in the sentence\n",
    "# 2. List of corresponding tags to the words\n",
    "\n",
    "for i in df.sentence_id.unique():\n",
    "    sentences.append(df[df.sentence_id == i].word.tolist())\n",
    "    y.append(df[df.sentence_id == i].Tag.tolist())\n",
    "\n",
    "print('First Sentence Words Sequence\\n', sentences[0])\n",
    "print('First Sentence Tags\\n', y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction\n",
    "\n",
    "In a sequence of sentence, for a word at position [t], the characteristics of the word can be expressed by its surrounding words in positions [t-1] and [t+1]\n",
    "\n",
    "We will therefore enhance the feature set by taking account of features of surrounding words.\n",
    "\n",
    "For each word in the sentence, the following features are extracted\n",
    "\n",
    "* **Word in Lowercase**    \n",
    "Word converted to lowercase  \n",
    "Features : word.lower, +1:word.lower, -1:word.lower  \n",
    "<br />  \n",
    "* **Word Shape**    \n",
    "Indicates whether word is number, uppercase, lowercase, capitalized, camelcase, mixedcase, wildcard, endingdot, abbrevation, contains-hyphen  \n",
    "Features : word.shape, +1:word.shape, -1:word.shape  \n",
    "<br />  \n",
    "* **Stemmed Word**  \n",
    "Normalized word using stemming. PorterStemmer api from nltk library used.    \n",
    "Features : word.stem, +1:word.stem, -1:word.stem   \n",
    "<br />  \n",
    "* **Lemmatized Word**    \n",
    "Normalized word using Lemmatization. WordLemmatizer api from nltk library used.  \n",
    "Features : word.lemma, +1:word.lemma, -1:word.lemma  \n",
    "<br />  \n",
    "* **Parts of Speech**     \n",
    "Extracts parts of speech of the word. pos_tag api from nltk library used.    \n",
    "Features : word.pos, +1:word.pos, -1:word.pos  \n",
    "Related features : word.pos[:2], +1:word.pos[:2], -1:word.pos[:2] - Implies last two characters of POS  \n",
    "<br />   \n",
    "* **Beginning or End of Sentence**  \n",
    "Indicates whether word is in beginning of sentence or end of sentence  \n",
    "Features : BOS, EOS  \n",
    "\n",
    "\n",
    "_Note: Features of previous word is denoted with a prefix '-1' and features of next word with prefix '+1'_ \n",
    "\n",
    "The features are stored in format required by sklearn-crfsuite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of words from First Sentence below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>word.lower</th>\n",
       "      <th>word.shape</th>\n",
       "      <th>word[-3:]</th>\n",
       "      <th>word[-2:]</th>\n",
       "      <th>word.stem</th>\n",
       "      <th>word.lemma</th>\n",
       "      <th>word.pos</th>\n",
       "      <th>word.pos[:2]</th>\n",
       "      <th>BOS</th>\n",
       "      <th>+1:word.lower</th>\n",
       "      <th>+1:word.shape</th>\n",
       "      <th>+1:word.stem</th>\n",
       "      <th>+1:word.lemma</th>\n",
       "      <th>+1:word.pos</th>\n",
       "      <th>+1:word.pos[:2]</th>\n",
       "      <th>-1:word.lower</th>\n",
       "      <th>-1:word.shape</th>\n",
       "      <th>-1:word.stem</th>\n",
       "      <th>-1:word.lemma</th>\n",
       "      <th>-1:word.pos</th>\n",
       "      <th>-1:word.pos[:2]</th>\n",
       "      <th>EOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>zambian</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>ian</td>\n",
       "      <td>an</td>\n",
       "      <td>zambian</td>\n",
       "      <td>zambian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>True</td>\n",
       "      <td>officials</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>offici</td>\n",
       "      <td>official</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>officials</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>als</td>\n",
       "      <td>ls</td>\n",
       "      <td>offici</td>\n",
       "      <td>official</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>say</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>zambian</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>zambian</td>\n",
       "      <td>zambian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>say</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>say</td>\n",
       "      <td>ay</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reports</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>report</td>\n",
       "      <td>report</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>officials</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>offici</td>\n",
       "      <td>official</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>reports</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>rts</td>\n",
       "      <td>ts</td>\n",
       "      <td>report</td>\n",
       "      <td>report</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>say</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>that</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>hat</td>\n",
       "      <td>at</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>president</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>presid</td>\n",
       "      <td>president</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>reports</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>report</td>\n",
       "      <td>report</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>president</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>ent</td>\n",
       "      <td>nt</td>\n",
       "      <td>presid</td>\n",
       "      <td>president</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>levy</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>levi</td>\n",
       "      <td>levy</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>that</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>levy</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>evy</td>\n",
       "      <td>vy</td>\n",
       "      <td>levi</td>\n",
       "      <td>levy</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>president</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>presid</td>\n",
       "      <td>president</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>asa</td>\n",
       "      <td>sa</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>ha</td>\n",
       "      <td>have</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VB</td>\n",
       "      <td>levy</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>levi</td>\n",
       "      <td>levy</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>has</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>has</td>\n",
       "      <td>as</td>\n",
       "      <td>ha</td>\n",
       "      <td>have</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>died</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>mwanawasa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>died</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>ied</td>\n",
       "      <td>ed</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>are</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>are</td>\n",
       "      <td>be</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>has</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>ha</td>\n",
       "      <td>have</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>are</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>are</td>\n",
       "      <td>re</td>\n",
       "      <td>are</td>\n",
       "      <td>be</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>uppercase</td>\n",
       "      <td>fals</td>\n",
       "      <td>false</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>died</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>false</td>\n",
       "      <td>uppercase</td>\n",
       "      <td>LSE</td>\n",
       "      <td>SE</td>\n",
       "      <td>fals</td>\n",
       "      <td>false</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>other</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>are</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>are</td>\n",
       "      <td>be</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>.</td>\n",
       "      <td>other</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>uppercase</td>\n",
       "      <td>fals</td>\n",
       "      <td>false</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bias word.lower   word.shape word[-3:] word[-2:]  word.stem word.lemma  \\\n",
       "0    1.0    zambian  capitalized       ian        an    zambian    zambian   \n",
       "1    1.0  officials    lowercase       als        ls     offici   official   \n",
       "2    1.0        say    lowercase       say        ay        say        say   \n",
       "3    1.0    reports    lowercase       rts        ts     report     report   \n",
       "4    1.0       that    lowercase       hat        at       that       that   \n",
       "5    1.0  president  capitalized       ent        nt     presid  president   \n",
       "6    1.0       levy  capitalized       evy        vy       levi       levy   \n",
       "7    1.0  mwanawasa  capitalized       asa        sa  mwanawasa  mwanawasa   \n",
       "8    1.0        has    lowercase       has        as         ha       have   \n",
       "9    1.0       died    lowercase       ied        ed        die        die   \n",
       "10   1.0        are    lowercase       are        re        are         be   \n",
       "11   1.0      false    uppercase       LSE        SE       fals      false   \n",
       "12   1.0          .        other         .         .          .          .   \n",
       "\n",
       "   word.pos word.pos[:2]   BOS +1:word.lower +1:word.shape +1:word.stem  \\\n",
       "0        JJ           JJ  True     officials     lowercase       offici   \n",
       "1       NNS           NN   NaN           say     lowercase          say   \n",
       "2       VBP           VB   NaN       reports     lowercase       report   \n",
       "3       NNS           NN   NaN          that     lowercase         that   \n",
       "4        IN           IN   NaN     president   capitalized       presid   \n",
       "5       NNP           NN   NaN          levy   capitalized         levi   \n",
       "6       NNP           NN   NaN     mwanawasa   capitalized    mwanawasa   \n",
       "7       NNP           NN   NaN           has     lowercase           ha   \n",
       "8       VBZ           VB   NaN          died     lowercase          die   \n",
       "9       VBN           VB   NaN           are     lowercase          are   \n",
       "10      VBP           VB   NaN         false     uppercase         fals   \n",
       "11      NNP           NN   NaN             .         other            .   \n",
       "12        .            .   NaN           NaN           NaN          NaN   \n",
       "\n",
       "   +1:word.lemma +1:word.pos +1:word.pos[:2] -1:word.lower -1:word.shape  \\\n",
       "0       official         NNS              NN           NaN           NaN   \n",
       "1            say         VBP              VB       zambian   capitalized   \n",
       "2         report         NNS              NN     officials     lowercase   \n",
       "3           that          IN              IN           say     lowercase   \n",
       "4      president         NNP              NN       reports     lowercase   \n",
       "5           levy         NNP              NN          that     lowercase   \n",
       "6      mwanawasa         NNP              NN     president   capitalized   \n",
       "7           have         VBZ              VB          levy   capitalized   \n",
       "8            die         VBN              VB     mwanawasa   capitalized   \n",
       "9             be         VBP              VB           has     lowercase   \n",
       "10         false         NNP              NN          died     lowercase   \n",
       "11             .           .               .           are     lowercase   \n",
       "12           NaN         NaN             NaN         false     uppercase   \n",
       "\n",
       "   -1:word.stem -1:word.lemma -1:word.pos -1:word.pos[:2]   EOS  \n",
       "0           NaN           NaN         NaN             NaN   NaN  \n",
       "1       zambian       zambian          JJ              JJ   NaN  \n",
       "2        offici      official         NNS              NN   NaN  \n",
       "3           say           say         VBP              VB   NaN  \n",
       "4        report        report         NNS              NN   NaN  \n",
       "5          that          that          IN              IN   NaN  \n",
       "6        presid     president         NNP              NN   NaN  \n",
       "7          levi          levy         NNP              NN   NaN  \n",
       "8     mwanawasa     mwanawasa         NNP              NN   NaN  \n",
       "9            ha          have         VBZ              VB   NaN  \n",
       "10          die           die         VBN              VB   NaN  \n",
       "11          are            be         VBP              VB   NaN  \n",
       "12         fals         false         NNP              NN  True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "\n",
    "print('Features of words from First Sentence below')\n",
    "pd.DataFrame(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training and Selection\n",
    "\n",
    "Now we will train a Linear-chain Conditional Random Fields model using `sklearn_crfsuite.CRF`\n",
    "\n",
    "Gradient descent using the L-BFGS method (default) is used with regularization.\n",
    "\n",
    "Instead of training the model with default regularization parameters (c1 = 0 and c2 = 1), we will search for optimal values using `sklearn.model_selection.RandomizedSearchCV` with 10 iterations\n",
    "\n",
    "5-fold cross validation used to assess performace of the model across combinations of c1 and c2 values. \n",
    "\n",
    "With the best found parameters, `RandomizedSearchCV` refits on the whole dataset by default.\n",
    "<br />  \n",
    "**Evaluation Metric for Model Selection**\n",
    "\n",
    "NER can be viewed as multi-class classification problem, where the IOB Tag `O` comprises of ~85% of all labels\n",
    "\n",
    "Predicting `O` as `O` is of least importance to us and it can be considered equivalent to predicting True Negatives in binary imbalance classification problem.\n",
    "\n",
    "True Positives, False Negatives and False Positives are of prime importance for each of the labels and therefore we will use F1 score as evaluation metric.  \n",
    "\n",
    "In a multiclass setting, the average parameter in the F1 score function needs to be additionally selected from the choices below\n",
    "\n",
    "* `micro` : calculates the F1 directly by using the global number of TP, FN and FP  \n",
    "\n",
    "   $F1_{class1 + class2 +...+classN}$\n",
    "<br />\n",
    "\n",
    "* `macro` : calculates the F1 separated by class but not using weights for the aggregation   \n",
    "   $F1_{class1}$ + $F1_{class2}$ +...+ $F1_{classN}$\n",
    "<br />\n",
    "\n",
    "* `weighted` :calculates F1 score for each class independently. Final F1 score is calculated using weights that depends on the number of true labels of each class:  \n",
    "\n",
    "    $F1_{class1}$ ∗ $W_{class1}$ + $F1_{class2}$ ∗ $W_{class2}$ +...+ $F1_{classN}$ ∗ $W_{classN}$    \n",
    "<br /> \n",
    "\n",
    "\n",
    "**As `macro` results in bigger penalisation when model does not perform well with the minority classes, we will choose F1 score average method macro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                                 verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000027EA041C4C8>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000027EA041C2C8>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, average=macro),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional Random Field Classifier\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=50,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "# Parameter Space for L1 (c1) and L2 (c2) regularization\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# Metric for evaluation - F1 Macro\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, average='macro')\n",
    "\n",
    "# Random Search with 5 fold CV and 10 Iterations\n",
    "rs = RandomizedSearchCV(crf, \n",
    "                        params_space,\n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=10,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_c1</th>\n",
       "      <th>param_c2</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.237254</td>\n",
       "      <td>0.607549</td>\n",
       "      <td>0.583862</td>\n",
       "      <td>0.038045</td>\n",
       "      <td>0.178438</td>\n",
       "      <td>0.00926184</td>\n",
       "      <td>{'c1': 0.1784380767345522,...</td>\n",
       "      <td>0.601596</td>\n",
       "      <td>0.575622</td>\n",
       "      <td>0.557357</td>\n",
       "      <td>0.566142</td>\n",
       "      <td>0.524956</td>\n",
       "      <td>0.565154</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.101852</td>\n",
       "      <td>0.787787</td>\n",
       "      <td>0.565443</td>\n",
       "      <td>0.115799</td>\n",
       "      <td>0.121397</td>\n",
       "      <td>0.0252306</td>\n",
       "      <td>{'c1': 0.1213965448781145,...</td>\n",
       "      <td>0.602550</td>\n",
       "      <td>0.575478</td>\n",
       "      <td>0.547397</td>\n",
       "      <td>0.562041</td>\n",
       "      <td>0.516134</td>\n",
       "      <td>0.560741</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.898455</td>\n",
       "      <td>1.124878</td>\n",
       "      <td>0.525207</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>0.0409881</td>\n",
       "      <td>0.0453177</td>\n",
       "      <td>{'c1': 0.0409881004896109,...</td>\n",
       "      <td>0.597227</td>\n",
       "      <td>0.589545</td>\n",
       "      <td>0.548005</td>\n",
       "      <td>0.573522</td>\n",
       "      <td>0.484864</td>\n",
       "      <td>0.558668</td>\n",
       "      <td>0.040528</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.967200</td>\n",
       "      <td>3.357283</td>\n",
       "      <td>0.873767</td>\n",
       "      <td>0.224575</td>\n",
       "      <td>0.192648</td>\n",
       "      <td>0.0295472</td>\n",
       "      <td>{'c1': 0.19264773048240638...</td>\n",
       "      <td>0.607505</td>\n",
       "      <td>0.546712</td>\n",
       "      <td>0.542714</td>\n",
       "      <td>0.542601</td>\n",
       "      <td>0.524160</td>\n",
       "      <td>0.552752</td>\n",
       "      <td>0.028480</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.368894</td>\n",
       "      <td>0.493842</td>\n",
       "      <td>0.569394</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>0.336635</td>\n",
       "      <td>0.00582753</td>\n",
       "      <td>{'c1': 0.3366353886188732,...</td>\n",
       "      <td>0.601378</td>\n",
       "      <td>0.531061</td>\n",
       "      <td>0.551974</td>\n",
       "      <td>0.543064</td>\n",
       "      <td>0.500577</td>\n",
       "      <td>0.545632</td>\n",
       "      <td>0.032846</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_c1  \\\n",
       "6      16.237254      0.607549         0.583862        0.038045   0.178438   \n",
       "0      15.101852      0.787787         0.565443        0.115799   0.121397   \n",
       "9      16.898455      1.124878         0.525207        0.093791  0.0409881   \n",
       "2      19.967200      3.357283         0.873767        0.224575   0.192648   \n",
       "5      16.368894      0.493842         0.569394        0.046388   0.336635   \n",
       "\n",
       "     param_c2                         params  split0_test_score  \\\n",
       "6  0.00926184  {'c1': 0.1784380767345522,...           0.601596   \n",
       "0   0.0252306  {'c1': 0.1213965448781145,...           0.602550   \n",
       "9   0.0453177  {'c1': 0.0409881004896109,...           0.597227   \n",
       "2   0.0295472  {'c1': 0.19264773048240638...           0.607505   \n",
       "5  0.00582753  {'c1': 0.3366353886188732,...           0.601378   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "6           0.575622           0.557357           0.566142           0.524956   \n",
       "0           0.575478           0.547397           0.562041           0.516134   \n",
       "9           0.589545           0.548005           0.573522           0.484864   \n",
       "2           0.546712           0.542714           0.542601           0.524160   \n",
       "5           0.531061           0.551974           0.543064           0.500577   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "6         0.565154        0.024951                1  \n",
       "0         0.560741        0.028747                2  \n",
       "9         0.558668        0.040528                3  \n",
       "2         0.552752        0.028480                4  \n",
       "5         0.545632        0.032846                5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract and View CV results\n",
    "cvresults = pd.DataFrame(rs.cv_results_)\n",
    "print(cvresults.shape)\n",
    "cvresults.sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.1784380767345522, 'c2': 0.009261842940762958}\n",
      "best CV score: 0.5651536706797567\n"
     ]
    }
   ],
   "source": [
    "# Print Best Parameters\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved best F1 Score (macro) of 0.5648 at c1 value 0.21 and c2-value  0.01\n",
    "\n",
    "\n",
    "Final estimator is refitted by `RandomizedSearchCV` on the entire dataset (X) with the above regulatization values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save Model\n",
    "\n",
    "The best estimator is extracted and saved in folder `model` for future scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model/ner_model.pickle\"\n",
    "pickle.dump(rs.best_estimator_, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope for further work\n",
    "\n",
    "\n",
    "Spacy and few other python libraries have open-sourced pre-trained NER models. These models can be further custom trained with our IOB tags.   \n",
    "\n",
    "\n",
    "Code example  \n",
    "https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "* [Named Entity Recognition and Classification](https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2)\n",
    "* [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
